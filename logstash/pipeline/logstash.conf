input {

	file {
		path => "/data/spark-logs/*/eventlog/*/*/eventlog*"
		codec => "json"
		mode => "read"
		start_position => "beginning"
		file_chunk_size => 32768000
	}
}

filter {
	mutate {
		remove_field => ["spark.executor.extraClassPath",
						 "spark.executor.extraJavaOptions",
						 "spark.executor.extraClassPath",
						 "spark.hadoop.spark.driverproxy.customHeadersToProperties",
						 "host"]
		# since time is in nanoseconds
		gsub => ["time", "\d{6}$", ""]
	}
	date {
		match => ["time", "UNIX_MS"]
		target => "@timestamp"
	}
}

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "elastic"
		password => "changeme"
		ecs_compatibility => disabled
	}
}
